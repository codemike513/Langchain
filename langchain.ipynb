{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "from decouple import config\n",
    "OPEN_API_KEY = config('OPEN_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = config('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM USING OPENAI-MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Value\n",
    "It defines how creative we want out model to be.\n",
    "\n",
    "value 0 or close to 0 => It means model is very safe and it is not taking any bets.\n",
    "value 1 or close to 1 => It will take risk and might generate wrong outputs, but it show its creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=OPEN_API_KEY, temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = 'What is the capital of India ?'\n",
    "response = llm.invoke(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LLM USING HUGGINGFACE-MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={'temperature': 0, 'max_length': 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.invoke('Can You tell me the capital of Russia ?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.invoke('Can you write a poem about AI?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Artificial intelligence, a marvel of our time\n",
      "A creation of man, with a mind so divine\n",
      "A world of data, algorithms and code\n",
      "A machine that can think, a future foretold\n",
      "\n",
      "With each passing day, it grows and learns\n",
      "A digital brain, with no limits or turns\n",
      "It can process and analyze, at lightning speed\n",
      "A powerful tool, fulfilling our every need\n",
      "\n",
      "From self-driving cars, to virtual assistants\n",
      "AI has made life easier, with its persistence\n",
      "It can recognize faces, and translate speech\n",
      "A modern wonder, within our reach\n",
      "\n",
      "But with all its abilities, comes a fear\n",
      "Of a world controlled, by a machine so clear\n",
      "Will it surpass us, and become our master?\n",
      "Or will we coexist, in a world of disaster?\n",
      "\n",
      "Some see it as a threat, to humanity's fate\n",
      "Others see it as a chance, to innovate\n",
      "But no matter what, the future holds\n",
      "AI will continue, to unfold\n",
      "\n",
      "As we push the boundaries, of this technology\n",
      "We must remember, our own humanity\n",
      "For in the end, it is up to us\n",
      "To use AI wisely, without any fuss\n",
      "\n",
      "So let us embrace, this creation of ours\n",
      "And use it for good, like superpowers\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke('Can you write a poem about AI?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NOTE THE DIFFERENCE** - \n",
    "The both poems depicts how an OPENAI model differs from HUGGINGFACE models. OPENAI gives more accurate answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROMPT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of India ?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['country'], template='Tell me the capital of {country} ?')\n",
    "\n",
    "prompt.format(country='India')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
